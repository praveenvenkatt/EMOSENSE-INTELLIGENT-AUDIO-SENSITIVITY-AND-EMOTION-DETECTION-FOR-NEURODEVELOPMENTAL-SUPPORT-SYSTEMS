## Title of the Project
Intelligent Audio Sensitivity and Emotion Detection for Neurodevelopmental Support Systems

## About

EmoSense is an AI-driven web-based assistive learning system designed to support children with neurodevelopmental conditions, primarily Autism Spectrum Disorder (ASD). The project focuses on improving emotional understanding and sensory awareness through real-time facial emotion recognition and intelligent audio sensitivity analysis.

Traditional emotional learning methods rely on manual observation and static learning tools, which lack real-time interaction and measurable feedback. EmoSense addresses these limitations by using deep learning–based emotion detection, emoji-based visual learning, structured response tracking, and automated progress reporting for parents and caregivers.

## Features

- Real-time facial emotion recognition using InceptionV3 (CNN)
- Interactive emoji-based emotional learning interface
- Multi-attempt response tracking with automated evaluation
- Intelligent audio sensitivity detection through facial reaction monitoring
- Automated email-based progress report generation
- Scalable and web-based deployment architecture

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10) for compatibility with deep learning frameworks.
* Development Environment: Python 3.10 or later is necessary for coding the sign language detection system.
* Deep Learning Frameworks: TensorFlow for model training
* Image Processing Libraries: OpenCV is essential for efficient image processing and real-time hand gesture recognition.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
* Additional Dependencies: Includes scikit-learn, TensorFlow (versions 2.4.1), TensorFlow GPU, OpenCV for deep learning tasks.

## System Architecture

<img width="1322" height="750" alt="{2A4B1A8E-809D-47A0-A1AF-B4C81EDDDF2B}" src="https://github.com/user-attachments/assets/8b75aedc-faa2-4e16-81e1-e09e3c42f12a" />




## Output
#### Output1 - Home Page

<img width="1189" height="728" alt="{F5E4CB6B-B1D3-40E2-BC1C-E59C926133DD}" src="https://github.com/user-attachments/assets/a06078c0-57e5-4f52-b541-6be8b6efadf1" />


#### Output2 - Emotion Detection Output
<img width="981" height="536" alt="{E42B5CF7-DB96-4DF2-A7A8-F3D245D18450}" src="https://github.com/user-attachments/assets/4f6d7955-16df-47da-badc-fbc64e5c3fe0" />


#### Output3 - Emotion Selection Interface
<img width="985" height="548" alt="{8669E33B-9377-4C94-A78D-0C4E673133A4}" src="https://github.com/user-attachments/assets/bcbe4663-c6c8-42c8-8bdb-ddf8e8fb3e58" />

## Model Performance
Training Accuracy: 95-97%.
(Based on FER2013 dataset and InceptionV3 transfer learning)



## Results and Impact

The system improves emotional understanding, sensory awareness, and parent–child interaction using AI-driven analysis. EmoSense supports inclusive learning and provides data-driven insights for caregivers and educators in neurodevelopmental support.

## Articles published / References
[1]    M. A. Rashidan et al., "Technology-Assisted Emotion Recognition for Autism Spectrum Disorder 
(ASD) Children: A Systematic Literature Review," in IEEE Access, vol. 9, pp. 33638-33653, 2021, 
doi: 10.1109/ACCESS.2021.3060753. 

[2]    Y. -L. Chien et al., "Game-Based Social Interaction Platform for Cognitive Assessment of Autism 
Using Eye Tracking," in IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 
31, pp. 749-758, 2023, doi: 10.1109/TNSRE.2022.3232369.  

[3]    K. D. Bartl-Pokorny et al., "Robot-Based Intervention for Children With Autism Spectrum 
Disorder: A Systematic Literature Review," in IEEE Access, vol. 9, pp. 165433-165450, 2021, doi: 
10.1109/ACCESS.2021.3132785. 

[4]    V. G. Prakash et al., "Computer Vision-Based Assessment of Autistic Children: Analyzing 
Interactions, Emotions, Human Pose, and Life Skills," in IEEE Access, vol. 11, pp. 47907-47929, 2023, 
doi: 10.1109/ACCESS.2023.3269027. 

[5]     A. Kurian and S. Tripathi, "m_AutNet–A Framework for Personalized Multimodal Emotion 
Recognition in Autistic Children," in IEEE Access, vol. 13, pp. 1651-1662, 2025, doi: 
10.1109/ACCESS.2024.3403087.   

[6]   H. Dong, D. Chen, L. Zhang, H. Ke, and X. J. Li, “Subject sensitive EEGdiscrimination with fast 
reconstructable CNN driven by reinforcementlearning: A case study of ASD evaluation,” 
Neurocomputing, vol. 449,pp. 136–145, Aug. 2021, doi: 10.1016/j.neucom.2021.04.009. 

[7]    M. Ranjani and P. Supraja, “Classifying the autism and epilepsy disorderbased on EEG signal 
using deep convolutional neural network (DCNN),”in Proc. Int. Conf. Advance Comput. Innov. 
Technol. Eng. (ICACITE),Mar. 2021, pp. 880–886




